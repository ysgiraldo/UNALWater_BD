{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c011c3-185f-45d1-a9bf-403fe7752cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas geopandas matplotlib faker pyspark pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5ea5b-d9d6-47f2-a488-e02cd7d7c355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+-----------+-----------+-----------------+--------+------------+------------+-------------+-------------+-------------------+\n",
      "|latitude|longitude|date|customer_id|employee_id|quantity_products|order_id|commune_code|commune_name|customer_name|employee_name|employee_commission|\n",
      "+--------+---------+----+-----------+-----------+-----------------+--------+------------+------------+-------------+-------------+-------------------+\n",
      "+--------+---------+----+-----------+-----------+-----------------+--------+------------+------------+-------------+-------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-------------------+-----------+-----------+-----------------+----------+------------+------------------------------------------+------------------+-----------------+-------------------+\n",
      "|latitude          |longitude         |date               |customer_id|employee_id|quantity_products|order_id  |commune_code|commune_name                              |customer_name     |employee_name    |employee_commission|\n",
      "+------------------+------------------+-------------------+-----------+-----------+-----------------+----------+------------+------------------------------------------+------------------+-----------------+-------------------+\n",
      "|6.250208574487932 |-75.5425665812484 |2023-07-13 08:41:51|7062       |1482       |99               |8946514217|08          |VILLA HERMOSA                             |Roth Coffey       |Elijah Parker    |0.13               |\n",
      "|6.228071965734311 |-75.5768274632126 |2024-04-29 09:38:36|8194       |1561       |25               |4272870731|15          |GUAYABAL                                  |Lillian Mcfarland |Amelia Nolan     |0.09               |\n",
      "|6.186861145396933 |-75.66999558602765|2024-01-29 23:03:13|5167       |9438       |92               |4510014982|80          |CORREGIMIENTO DE SAN ANTONIO DE PRADO     |Owen Moon         |Dacey Barr       |0.02               |\n",
      "|6.220996451961138 |-75.69543104864859|2024-04-25 10:54:37|3711       |9726       |50               |9513211933|80          |CORREGIMIENTO DE SAN ANTONIO DE PRADO     |Amelia Miles      |Christen Hamilton|0.17               |\n",
      "|6.249629041691136 |-75.50616564613885|2024-05-21 08:01:22|7671       |6337       |75               |5364827120|90          |CORREGIMIENTO DE SANTA ELENA              |Zenia Grimes      |Phyllis Hubbard  |0.1                |\n",
      "|6.190211847416741 |-75.48524748869679|2024-03-18 12:09:44|1958       |1679       |44               |239082515 |90          |CORREGIMIENTO DE SANTA ELENA              |Valentine Pugh    |Darius Greer     |0.04               |\n",
      "|6.236308855861064 |-75.4847323284472 |2023-10-19 23:21:45|6228       |9726       |53               |6440541417|90          |CORREGIMIENTO DE SANTA ELENA              |Beatrice Gamble   |Christen Hamilton|0.17               |\n",
      "|6.3323864547198685|-75.71381118315956|2023-09-24 04:54:11|7062       |9726       |93               |4148385712|50          |CORREGIMIENTO DE SAN SEBASTIÁN DE PALMITAS|Roth Coffey       |Christen Hamilton|0.17               |\n",
      "|6.2464999341761445|-75.66236682164066|2023-11-19 09:58:54|7896       |4750       |68               |3870154982|70          |CORREGIMIENTO DE ALTAVISTA                |Jena Zimmerman    |Howard Guthrie   |0.16               |\n",
      "|6.199869073353152 |-75.68295774407805|2023-11-28 12:38:27|6899       |1482       |23               |1076858504|80          |CORREGIMIENTO DE SAN ANTONIO DE PRADO     |Harrison Olsen    |Elijah Parker    |0.13               |\n",
      "|6.191449537196454 |-75.64963069290246|2023-09-27 19:52:28|6789       |1679       |63               |5962031668|80          |CORREGIMIENTO DE SAN ANTONIO DE PRADO     |Mufutau Dudley    |Darius Greer     |0.04               |\n",
      "|6.203951491520839 |-75.6201480385961 |2023-01-17 19:51:42|2930       |1561       |43               |5244218094|70          |CORREGIMIENTO DE ALTAVISTA                |Brendan Norton    |Amelia Nolan     |0.09               |\n",
      "|6.204284645841372 |-75.50807806520373|2024-04-04 07:49:11|9443       |4942       |37               |5010528063|90          |CORREGIMIENTO DE SANTA ELENA              |Imani Wood        |Sydnee Kirby     |0.16               |\n",
      "|6.295516161336374 |-75.55093773713368|2024-05-30 20:19:14|4347       |9726       |88               |1151777552|02          |SANTA CRUZ                                |Byron Carter      |Christen Hamilton|0.17               |\n",
      "|6.339732980761648 |-75.68375300796093|2023-04-08 00:58:58|5003       |5668       |60               |4514291345|50          |CORREGIMIENTO DE SAN SEBASTIÁN DE PALMITAS|Felicia Macias    |Melanie Ball     |0.18               |\n",
      "|6.256180649387506 |-75.54320481593791|2023-10-05 15:41:56|4388       |9726       |61               |8357979649|08          |VILLA HERMOSA                             |Josephine Small   |Christen Hamilton|0.17               |\n",
      "|6.338780079042087 |-75.70876051454104|2024-04-04 23:48:33|6709       |9438       |47               |8425385224|50          |CORREGIMIENTO DE SAN SEBASTIÁN DE PALMITAS|Rhoda Rojas       |Dacey Barr       |0.02               |\n",
      "|6.346864321997172 |-75.70551445199357|2024-05-17 16:37:52|4419       |1679       |86               |9736732322|50          |CORREGIMIENTO DE SAN SEBASTIÁN DE PALMITAS|Valentine Cox     |Darius Greer     |0.04               |\n",
      "|6.204503451655489 |-75.58687531763152|2023-07-28 04:16:59|5859       |9435       |55               |2125904736|15          |GUAYABAL                                  |Kathleen Davenport|Ryan Nichols     |0.18               |\n",
      "|6.238927389570066 |-75.53864010294855|2023-10-26 16:52:48|3372       |3455       |64               |9329999242|08          |VILLA HERMOSA                             |Axel Solis        |Davis Jenkins    |0.13               |\n",
      "+------------------+------------------+-------------------+-----------+-----------+-----------------+----------+------------+------------------------------------------+------------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Capa bronze data cruda\n",
    "####\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, IntegerType, TimestampType\n",
    "\n",
    "# Crear sesión de Spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"SparkStreamingFromSocket\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Definir el esquema para los datos JSON que se recibirán\n",
    "schema = StructType() \\\n",
    "    .add(\"latitude\", DoubleType()) \\\n",
    "    .add(\"longitude\", DoubleType()) \\\n",
    "    .add(\"date\", TimestampType()) \\\n",
    "    .add(\"customer_id\", StringType()) \\\n",
    "    .add(\"employee_id\", StringType()) \\\n",
    "    .add(\"quantity_products\", IntegerType()) \\\n",
    "    .add(\"order_id\", StringType()) \\\n",
    "    .add(\"commune_code\", StringType()) \\\n",
    "    .add(\"commune_name\", StringType()) \\\n",
    "    .add(\"customer_name\", StringType()) \\\n",
    "    .add(\"employee_name\", StringType()) \\\n",
    "    .add(\"employee_commission\", DoubleType())\n",
    "\n",
    "# Leer datos desde el socket\n",
    "streaming_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", 12345) \\\n",
    "    .load()\n",
    "\n",
    "# Parsear los datos JSON utilizando el esquema definido\n",
    "parsed_df = streaming_df \\\n",
    "    .select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"parsed_value\")) \\\n",
    "    .select(\"parsed_value.*\")\n",
    "\n",
    "# Función para guardar los datos recibidos en bronze\n",
    "def process_data(df, epoch_id):\n",
    "    try:\n",
    "        hdfs_path = \"/user/root/bronze\"\n",
    "        df.write \\\n",
    "          .format(\"parquet\") \\\n",
    "          .mode(\"append\") \\\n",
    "          .save(hdfs_path)\n",
    "        df.show(truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar los datos: {e}\")\n",
    "        \n",
    "# Escribir los resultados en la consola\n",
    "query = parsed_df \\\n",
    "    .writeStream \\\n",
    "    .foreachBatch(process_data) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "\n",
    "# Mantener el stream en ejecución\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef945523-5155-477f-83b1-3325e81b1a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros procesados en silver después de transformar: 500\n",
      "root\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- quantity_products: integer (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- commune_code: string (nullable = true)\n",
      " |-- commune_name: string (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- employee_commission: double (nullable = true)\n",
      " |-- price: integer (nullable = false)\n",
      " |-- sales: integer (nullable = true)\n",
      " |-- commission_value: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- day_week: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- minute: integer (nullable = true)\n",
      " |-- second: integer (nullable = true)\n",
      "\n",
      "+------------------+------------------+-------------------+-----------+-----------+-----------------+----------+------------+--------------------+------------------+-----------------+-------------------+-----+------+----------------+----+-----+---+--------+----+------+------+\n",
      "|          latitude|         longitude|               date|customer_id|employee_id|quantity_products|  order_id|commune_code|        commune_name|     customer_name|    employee_name|employee_commission|price| sales|commission_value|year|month|day|day_week|hour|minute|second|\n",
      "+------------------+------------------+-------------------+-----------+-----------+-----------------+----------+------------+--------------------+------------------+-----------------+-------------------+-----+------+----------------+----+-----+---+--------+----+------+------+\n",
      "| 6.250208574487932| -75.5425665812484|2023-07-13 08:41:51|       7062|       1482|               99|8946514217|          08|       VILLA HERMOSA|       Roth Coffey|    Elijah Parker|               0.13| 3500|346500|         45045.0|2023|    7| 13|       5|   8|    41|    51|\n",
      "| 6.228071965734311| -75.5768274632126|2024-04-29 09:38:36|       8194|       1561|               25|4272870731|          15|            GUAYABAL| Lillian Mcfarland|     Amelia Nolan|               0.09| 3500| 87500|          7875.0|2024|    4| 29|       2|   9|    38|    36|\n",
      "| 6.186861145396933|-75.66999558602765|2024-01-29 23:03:13|       5167|       9438|               92|4510014982|          80|CORREGIMIENTO DE ...|         Owen Moon|       Dacey Barr|               0.02| 3500|322000|          6440.0|2024|    1| 29|       2|  23|     3|    13|\n",
      "| 6.220996451961138|-75.69543104864859|2024-04-25 10:54:37|       3711|       9726|               50|9513211933|          80|CORREGIMIENTO DE ...|      Amelia Miles|Christen Hamilton|               0.17| 3500|175000|         29750.0|2024|    4| 25|       5|  10|    54|    37|\n",
      "| 6.249629041691136|-75.50616564613885|2024-05-21 08:01:22|       7671|       6337|               75|5364827120|          90|CORREGIMIENTO DE ...|      Zenia Grimes|  Phyllis Hubbard|                0.1| 3500|262500|         26250.0|2024|    5| 21|       3|   8|     1|    22|\n",
      "| 6.190211847416741|-75.48524748869679|2024-03-18 12:09:44|       1958|       1679|               44| 239082515|          90|CORREGIMIENTO DE ...|    Valentine Pugh|     Darius Greer|               0.04| 3500|154000|          6160.0|2024|    3| 18|       2|  12|     9|    44|\n",
      "| 6.236308855861064| -75.4847323284472|2023-10-19 23:21:45|       6228|       9726|               53|6440541417|          90|CORREGIMIENTO DE ...|   Beatrice Gamble|Christen Hamilton|               0.17| 3500|185500|         31535.0|2023|   10| 19|       5|  23|    21|    45|\n",
      "|6.3323864547198685|-75.71381118315956|2023-09-24 04:54:11|       7062|       9726|               93|4148385712|          50|CORREGIMIENTO DE ...|       Roth Coffey|Christen Hamilton|               0.17| 3500|325500|         55335.0|2023|    9| 24|       1|   4|    54|    11|\n",
      "|6.2464999341761445|-75.66236682164066|2023-11-19 09:58:54|       7896|       4750|               68|3870154982|          70|CORREGIMIENTO DE ...|    Jena Zimmerman|   Howard Guthrie|               0.16| 3500|238000|         38080.0|2023|   11| 19|       1|   9|    58|    54|\n",
      "| 6.204503451655489|-75.58687531763152|2023-07-28 04:16:59|       5859|       9435|               55|2125904736|          15|            GUAYABAL|Kathleen Davenport|     Ryan Nichols|               0.18| 3500|192500|         34650.0|2023|    7| 28|       6|   4|    16|    59|\n",
      "| 6.238927389570066|-75.53864010294855|2023-10-26 16:52:48|       3372|       3455|               64|9329999242|          08|       VILLA HERMOSA|        Axel Solis|    Davis Jenkins|               0.13| 3500|224000|         29120.0|2023|   10| 26|       5|  16|    52|    48|\n",
      "| 6.201890307512778|-75.51864011501209|2024-04-02 11:47:20|       9585|       2232|               38| 305964666|          90|CORREGIMIENTO DE ...|        Lamar Pace|  Forrest Bradley|               0.07| 3500|133000|          9310.0|2024|    4|  2|       3|  11|    47|    20|\n",
      "| 6.245089889388844| -75.5421900260397|2023-07-12 07:19:56|       1912|       6659|               41|2168419294|          08|       VILLA HERMOSA|       Abdul Hobbs|       Melinda Le|               0.06| 3500|143500|          8610.0|2023|    7| 12|       4|   7|    19|    56|\n",
      "| 6.318188623012783|-75.67203008996682|2023-04-10 18:28:28|       1983|       9726|               86| 243778726|          50|CORREGIMIENTO DE ...|    Rigel Fletcher|Christen Hamilton|               0.17| 3500|301000|         51170.0|2023|    4| 10|       2|  18|    28|    28|\n",
      "| 6.265038132687734| -75.6838589778932|2024-05-26 05:32:34|       9869|       3455|               81|3056785452|          80|CORREGIMIENTO DE ...|     James Mathews|    Davis Jenkins|               0.13| 3500|283500|         36855.0|2024|    5| 26|       1|   5|    32|    34|\n",
      "| 6.331744741863468| -75.7022883590779|2023-04-30 06:57:49|       4082|       8362|               65|9226409985|          50|CORREGIMIENTO DE ...|        Maite Frye|   Catherine King|               0.07| 3500|227500|         15925.0|2023|    4| 30|       1|   6|    57|    49|\n",
      "| 6.286833323509598|-75.51491141040887|2023-03-07 01:57:03|       4211|       9438|               91|4728563943|          90|CORREGIMIENTO DE ...|      Elvis Bolton|       Dacey Barr|               0.02| 3500|318500|          6370.0|2023|    3|  7|       3|   1|    57|     3|\n",
      "| 6.204385624493366|-75.65477667557407|2024-03-11 09:49:19|       9481|       3830|               96|6568757197|          80|CORREGIMIENTO DE ...|    Odette Beasley| Shaeleigh Turner|               0.06| 3500|336000|         20160.0|2024|    3| 11|       2|   9|    49|    19|\n",
      "| 6.257846491634125|-75.66364763940958|2023-09-14 05:51:47|       9188|       9438|               85|6425101658|          60|CORREGIMIENTO DE ...|     Blythe Ingram|       Dacey Barr|               0.02| 3500|297500|          5950.0|2023|    9| 14|       5|   5|    51|    47|\n",
      "| 6.260059218944603|-75.58120921056367|2023-09-23 19:06:48|       4922|       1473|               76|8611654114|          07|             ROBLEDO|       Lenore Rice|    Celeste Johns|               0.07| 3500|266000|         18620.0|2023|    9| 23|       7|  19|     6|    48|\n",
      "+------------------+------------------+-------------------+-----------+-----------+-----------------+----------+------------+--------------------+------------------+-----------------+-------------------+-----+------+----------------+----+-----+---+--------+----+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Capa silver procesamiento\n",
    "####\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, expr, round, lit, year, month, dayofmonth, trim, hour, minute, second, dayofweek\n",
    "import os \n",
    "\n",
    "# Obtener la sesión de Spark existente si está activa\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Función para leer archivos Parquet desde HDFS\n",
    "def leer_archivos_parquet(path: str) -> DataFrame:\n",
    "    try:\n",
    "        # Verificar la existencia del archivo antes de leerlo\n",
    "        if os.system(f\"hdfs dfs -test -e {path}\") == 0:\n",
    "            return spark.read.parquet(path)\n",
    "        else:\n",
    "            print(f\"El archivo Parquet {path} no existe.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo Parquet {path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Ruta de bronze\n",
    "bronze_path = \"hdfs:///user/root/bronze\"  \n",
    "\n",
    "# Leer archivos Parquet desde el directorio en HDFS\n",
    "df_bronze = leer_archivos_parquet(bronze_path)\n",
    "\n",
    "# Función para agregar una columna con valor constante al precio y dividir la fecha\n",
    "def transformar_df(df: DataFrame) -> DataFrame:\n",
    "        df_transformado = df \\\n",
    "            .withColumn(\"price\", lit(3500)) \\\n",
    "            .withColumn(\"sales\", col(\"quantity_products\") * col(\"price\")) \\\n",
    "            .withColumn(\"commission_value\", round(col(\"sales\") * col(\"employee_commission\"), 0)) \\\n",
    "            .withColumn(\"customer_name\", trim(col(\"customer_name\"))) \\\n",
    "            .withColumn(\"employee_name\", trim(col(\"employee_name\"))) \\\n",
    "            .withColumn(\"commune_name\", trim(col(\"commune_name\"))) \\\n",
    "            .withColumn(\"year\", year(col(\"date\"))) \\\n",
    "            .withColumn(\"month\", month(col(\"date\"))) \\\n",
    "            .withColumn(\"day\", dayofmonth(col(\"date\"))) \\\n",
    "            .withColumn(\"day_week\", dayofweek(col(\"date\"))) \\\n",
    "            .withColumn(\"hour\", hour(col(\"date\"))) \\\n",
    "            .withColumn(\"minute\", minute(col(\"date\"))) \\\n",
    "            .withColumn(\"second\", second(col(\"date\")))\n",
    "        return df_transformado\n",
    "\n",
    "# Función para guardar DataFrame en un archivo Parquet en la capa Silver, siempre sobreescribe esto es compactar\n",
    "def guardar_archivo_parquet(df: DataFrame, path: str) -> None:\n",
    "    df.coalesce(1).write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(path)\n",
    "        \n",
    "# Función principal para unir archivos de Bronze a Silver\n",
    "def unir_archivos_bronze_a_silver(bronze_path: str, silver_path: str) -> None:\n",
    "    # Leer archivos Parquet desde la capa Bronze\n",
    "    df_bronze = leer_archivos_parquet(bronze_path)\n",
    "\n",
    "    # Transformar el DataFrame de Bronze\n",
    "    df_transformado = transformar_df(df_bronze)\n",
    "\n",
    "    # Guardar el DataFrame transformado en la capa Silver\n",
    "    guardar_archivo_parquet(df_transformado, silver_path)\n",
    "\n",
    "    # Leer archivos Parquet desde la capa Silver después de transformar\n",
    "    df_silver_transformado = leer_archivos_parquet(silver_path)\n",
    "\n",
    "    if df_silver_transformado is not None:\n",
    "        # Contar la cantidad de registros en la capa Silver después de transformar\n",
    "        records_processed = df_silver_transformado.count()\n",
    "        print(f\"Cantidad de registros procesados en silver después de transformar: {records_processed}\")\n",
    "    \n",
    "    # Mostrar el DataFrame transformado (opcional)\n",
    "    df_transformado.printSchema()\n",
    "    df_transformado.show()\n",
    "\n",
    "# Rutas en hdfs (distrbuido)\n",
    "bronze_path = \"hdfs:///user/root/bronze\"  \n",
    "silver_path = \"hdfs:///user/root/silver/unificado.parquet\"  \n",
    "\n",
    "# Ejecutar el proceso de unión\n",
    "unir_archivos_bronze_a_silver(bronze_path, silver_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a18a1d5-ecc2-472c-a447-dee198098c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estructura de la tabla UNALWater:\n",
      "+-------------------+---------+-------+\n",
      "|           col_name|data_type|comment|\n",
      "+-------------------+---------+-------+\n",
      "|           latitude|   double|   null|\n",
      "|          longitude|   double|   null|\n",
      "|        customer_id|   string|   null|\n",
      "|        employee_id|   string|   null|\n",
      "|  quantity_products|      int|   null|\n",
      "|           order_id|   string|   null|\n",
      "|       commune_code|   string|   null|\n",
      "|       commune_name|   string|   null|\n",
      "|      customer_name|   string|   null|\n",
      "|      employee_name|   string|   null|\n",
      "|employee_commission|   double|   null|\n",
      "|              price|      int|   null|\n",
      "|              sales|      int|   null|\n",
      "|   commission_value|   double|   null|\n",
      "|               year|      int|   null|\n",
      "|              month|      int|   null|\n",
      "|                day|      int|   null|\n",
      "|           day_week|      int|   null|\n",
      "|               hour|      int|   null|\n",
      "|             minute|      int|   null|\n",
      "+-------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Comportamiento de la cantidad de ventas por comuna:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------+\n",
      "|Comuna_Corregimiento|Cantidad_Productos|Total_Ventas|\n",
      "+--------------------+------------------+------------+\n",
      "|         SANTA ELENA|              6232|    21812000|\n",
      "|SAN SEBASTIAN DE ...|              4945|    17307500|\n",
      "|SAN ANTONIO DE PRADO|              4330|    15155000|\n",
      "|       SAN CRISTOBAL|              3888|    13608000|\n",
      "|           ALTAVISTA|              1905|     6667500|\n",
      "|          EL POBLADO|              1204|     4214000|\n",
      "|             ROBLEDO|               926|     3241000|\n",
      "|       VILLA HERMOSA|               869|     3041500|\n",
      "|    LAURELES ESTADIO|               804|     2814000|\n",
      "|        BUENOS AIRES|               721|     2523500|\n",
      "|               BELÉN|               660|     2310000|\n",
      "|            GUAYABAL|               531|     1858500|\n",
      "|       LA CANDELARIA|               487|     1704500|\n",
      "|            CASTILLA|               475|     1662500|\n",
      "|            ARANJUEZ|               372|     1302000|\n",
      "|             POPULAR|               297|     1039500|\n",
      "|            MANRIQUE|               263|      920500|\n",
      "|          LA AMÉRICA|               235|      822500|\n",
      "|          SANTA CRUZ|               196|      686000|\n",
      "|          SAN JAVIER|               193|      675500|\n",
      "+--------------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Comportamiento de la cantidad de ventas por vendedor:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+------------+--------------+\n",
      "|         Vendedor|Cantidad_Productos|Total_Ventas|Valor_Comision|\n",
      "+-----------------+------------------+------------+--------------+\n",
      "|Christen Hamilton|              2010|     7035000|     1195950.0|\n",
      "|     Melanie Ball|              1618|     5663000|     1019340.0|\n",
      "|     Sydnee Kirby|              1526|     5341000|      854560.0|\n",
      "|   Howard Guthrie|              1273|     4455500|      712880.0|\n",
      "|  Althea Mckenzie|              1540|     5390000|      700700.0|\n",
      "|       Ori Tucker|              1786|     6251000|      625100.0|\n",
      "|  Phyllis Hubbard|              1773|     6205500|      620550.0|\n",
      "|    Elijah Parker|              1355|     4742500|      616525.0|\n",
      "|    Bevis Sanford|              1111|     3888500|      544390.0|\n",
      "|     Ryan Nichols|               838|     2933000|      527940.0|\n",
      "|    Davis Jenkins|              1095|     3832500|      498225.0|\n",
      "|   Catherine King|              1877|     6569500|      459865.0|\n",
      "|     Amelia Nolan|              1334|     4669000|      420210.0|\n",
      "| Shaeleigh Turner|              1790|     6265000|      375900.0|\n",
      "|  Forrest Bradley|              1404|     4914000|      343980.0|\n",
      "|       Melinda Le|              1495|     5232500|      313950.0|\n",
      "|    Celeste Johns|              1012|     3542000|      247940.0|\n",
      "|     Darius Greer|              1757|     6149500|      245980.0|\n",
      "|     Patricia Cox|              1579|     5526500|      221060.0|\n",
      "|       Dacey Barr|              1481|     5183500|      103670.0|\n",
      "+-----------------+------------------+------------+--------------+\n",
      "\n",
      "Los 10 clientes que más nos han comprado botellas de agua:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+------------+\n",
      "|          Cliente|Cantidad_Productos|Total_Ventas|\n",
      "+-----------------+------------------+------------+\n",
      "|        Knox Best|               350|     1225000|\n",
      "|    Amery Shepard|               270|      945000|\n",
      "|      Roth Coffey|               264|      924000|\n",
      "|    Heather Oneil|               263|      920500|\n",
      "|     Elvis Bolton|               260|      910000|\n",
      "|   Zenia Cardenas|               255|      892500|\n",
      "|       Xyla Kelly|               245|      857500|\n",
      "|   Galena Fleming|               233|      815500|\n",
      "|  Colorado Torres|               232|      812000|\n",
      "|Lillian Mcfarland|               232|      812000|\n",
      "+-----------------+------------------+------------+\n",
      "\n",
      "Comportamiento de ventas de botellas de agua por día de la semana:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:==========================================>             (12 + 4) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------+\n",
      "|Dia_Semana|Cantidad_Productos|Total_Ventas|\n",
      "+----------+------------------+------------+\n",
      "|    Jueves|              5012|    17542000|\n",
      "|    Martes|              4784|    16744000|\n",
      "|   Domingo|              4494|    15729000|\n",
      "|    Sábado|              4342|    15197000|\n",
      "|     Lunes|              3916|    13706000|\n",
      "| Miércoles|              3663|    12820500|\n",
      "|   Viernes|              3443|    12050500|\n",
      "+----------+------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#### Capa gold\n",
    "####\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import sum, max, min, avg, count, col\n",
    "\n",
    "# Obtener la sesión de Spark existente si está activa\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Ruta del archivo Parquet en la capa Silver\n",
    "silver_path = \"hdfs:///user/root/silver/unificado.parquet\"\n",
    "\n",
    "# Leer los datos desde el archivo Parquet en la capa Silver\n",
    "df = spark.read.parquet(silver_path)\n",
    "\n",
    "# Crear la base de datos si no existe\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS UNALwater\")\n",
    "\n",
    "# Establecer la base de datos en uso\n",
    "spark.sql(\"USE UNALwater\")\n",
    "\n",
    "# Definir la ruta en HDFS donde se guardará la tabla en formato Parquet en la capa Gold\n",
    "gold_path = \"hdfs:///user/root/gold/UNALWater\"\n",
    "\n",
    "# Insertar el dataframe en una tabla externa UNALWater particionada por el campo 'date'\n",
    "df.write.mode(\"append\") \\\n",
    "  .partitionBy(\"date\") \\\n",
    "  .format(\"parquet\") \\\n",
    "  .option(\"path\", gold_path) \\\n",
    "  .saveAsTable(\"UNALWater\")\n",
    "\n",
    "# Mostrar la estructura de la tabla\n",
    "print(\"Estructura de la tabla UNALWater:\")\n",
    "spark.sql(\"DESCRIBE UNALWater\").show()\n",
    "\n",
    "# Construir y ejecutar consultas SQL para responder preguntas de negocio\n",
    "query_ventas_por_comuna = \"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN commune_name LIKE '%CORREGIMIENTO DE SAN SEBAS%' THEN 'SAN SEBASTIAN DE PALMITAS'\n",
    "            WHEN commune_name LIKE '%CORREGIMIENTO DE SAN CRIS%' THEN 'SAN CRISTOBAL'\n",
    "            WHEN commune_name = 'CORREGIMIENTO DE ALTAVISTA' THEN 'ALTAVISTA'\n",
    "            WHEN commune_name = 'CORREGIMIENTO DE SANTA ELENA' THEN 'SANTA ELENA'\n",
    "            WHEN commune_name = 'CORREGIMIENTO DE SAN ANTONIO DE PRADO' THEN 'SAN ANTONIO DE PRADO'\n",
    "        ELSE commune_name END AS Comuna_Corregimiento,\n",
    "        SUM(quantity_products) AS Cantidad_Productos,\n",
    "        SUM(sales) AS Total_Ventas\n",
    "    FROM UNALWater\n",
    "    GROUP BY Comuna_Corregimiento\n",
    "    ORDER BY Total_Ventas DESC;\n",
    "\"\"\"\n",
    "\n",
    "query_ventas_por_vendedor = \"\"\"\n",
    "    SELECT \n",
    "        employee_name AS Vendedor,\n",
    "        SUM(quantity_products) AS Cantidad_Productos,\n",
    "        SUM(sales) AS Total_Ventas,\n",
    "        SUM(commission_value) AS Valor_Comision\n",
    "    FROM UNALWater\n",
    "    GROUP BY employee_name\n",
    "    ORDER BY Valor_Comision DESC\n",
    "\"\"\"\n",
    "\n",
    "query_top10_por_clientes = \"\"\"\n",
    "    SELECT \n",
    "        customer_name AS Cliente,\n",
    "        SUM(quantity_products) AS Cantidad_Productos,\n",
    "        SUM(sales) AS Total_Ventas\n",
    "    FROM UNALWater\n",
    "    GROUP BY customer_name\n",
    "    ORDER BY Total_Ventas DESC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "query_ventas_por_dia = \"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN day_week = 1 THEN 'Domingo' \n",
    "            WHEN day_week = 2 THEN 'Lunes' \n",
    "            WHEN day_week = 3 THEN 'Martes'\n",
    "            WHEN day_week = 4 THEN 'Miércoles'\n",
    "            WHEN day_week = 5 THEN 'Jueves'\n",
    "            WHEN day_week = 6 THEN 'Viernes'\n",
    "            WHEN day_week = 7 THEN 'Sábado'\n",
    "        END AS Dia_Semana,\n",
    "        SUM(quantity_products) AS Cantidad_Productos,\n",
    "        SUM(sales) AS Total_Ventas\n",
    "    FROM UNALWater\n",
    "    GROUP BY day_week\n",
    "    ORDER BY Total_Ventas DESC\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar las consultas SQL y mostrar los resultados\n",
    "ventas_por_comuna = spark.sql(query_ventas_por_comuna)\n",
    "print(\"Comportamiento de la cantidad de ventas por comuna:\")\n",
    "ventas_por_comuna.show()\n",
    "\n",
    "ventas_por_vendedor = spark.sql(query_ventas_por_vendedor)\n",
    "print(\"Comportamiento de la cantidad de ventas por vendedor:\")\n",
    "ventas_por_vendedor.show()\n",
    "\n",
    "top10_por_clientes = spark.sql(query_top10_por_clientes)\n",
    "print(\"Los 10 clientes que más nos han comprado botellas de agua:\")\n",
    "top10_por_clientes.show()\n",
    "\n",
    "ventas_por_dia = spark.sql(query_ventas_por_dia)\n",
    "print(\"Comportamiento de ventas de botellas de agua por día de la semana:\")\n",
    "ventas_por_dia.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a001f-050e-4e8f-b019-ab1c11ca0984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - root supergroup          0 2024-06-20 04:13 /user/root/gold/UNALWater\n"
     ]
    }
   ],
   "source": [
    "#!hdfs dfs -ls /user/root/silver/unificado.parquet\n",
    "#!hdfs dfs -mkdir -p /user/root/gold\n",
    "#!hdfs dfs -ls /user/root/bronze\n",
    "#!hdfs dfs -ls /user/root\n",
    "#!hdfs dfs -copyToLocal /user/root/gold /Analitica/BigData/Final/gold\n",
    "#!hdfs dfs -copyFromLocal medellin_neighborhoods.parquet /user/root/bronze\n",
    "#!hdfs dfs -ls /user/root/silver\n",
    "!hdfs dfs -ls /user/root/gold\n",
    "#!hdfs dfs -ls /user/root/bronze\n",
    "#!hdfs dfs -ls /user/root/bronze | grep medellin_neighborhoods.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57988c48-78c4-46a2-a49b-47e97af30764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear la sesión de Spark con configuración ajustada\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Definir la ruta del archivo Parquet con datos de ventas en la capa Silver\n",
    "cargue_inicial_path = 'hdfs:///user/root/silver/unificado.parquet'\n",
    "\n",
    "try:\n",
    "    # Cargar el archivo Parquet de cargue inicial como un DataFrame de Spark\n",
    "    df_cargue = spark.read.parquet(cargue_inicial_path).limit(10)  # Limitar a 10 registros para pruebas\n",
    "\n",
    "    # Definir la función Python para crear puntos a partir de latitud y longitud\n",
    "    def create_point(longitude, latitude):\n",
    "        return Point(float(longitude), float(latitude))\n",
    "\n",
    "    # Registrar la función como una UDF (User Defined Function) en Spark\n",
    "    create_point_udf = udf(create_point, returnType=FloatType())\n",
    "\n",
    "    # Convertir las columnas de longitud y latitud a tipo Float y crear columna 'geom'\n",
    "    df_cargue = df_cargue.withColumn('longitude', col('longitude').cast(FloatType())) \\\n",
    "                         .withColumn('latitude', col('latitude').cast(FloatType())) \\\n",
    "                         .withColumn('geom', create_point_udf(col('longitude'), col('latitude')))\n",
    "    df_cargue.show()\n",
    "#     # Convertir el DataFrame de Spark en un GeoDataFrame de GeoPandas\n",
    "#     gdf_cargue = gpd.GeoDataFrame(df_cargue.toPandas(), geometry='geom')\n",
    "    \n",
    "#     # Imprimir las primeras filas para verificar la conversión\n",
    "#     print(\"Primeras filas de GeoDataFrame:\")\n",
    "#     print(gdf_cargue.head())\n",
    "\n",
    "#     # Definir la ruta del archivo Parquet con geometrías de Medellín en la capa Bronze\n",
    "#     medellin_neighborhoods_path = 'hdfs:///user/root/bronze/medellin_neighborhoods.parquet'\n",
    "    \n",
    "#     # Cargar el archivo Parquet de geometrías de Medellín como un GeoDataFrame de GeoPandas\n",
    "#     medellin_neighborhoods = gpd.read_parquet(medellin_neighborhoods_path)\n",
    "    \n",
    "#     # Imprimir las primeras filas para verificar la carga de datos\n",
    "#     print(\"\\nPrimeras filas de medellin_neighborhoods GeoDataFrame:\")\n",
    "#     print(medellin_neighborhoods.head())\n",
    "\n",
    "# #     # Crear el gráfico con las geometrías de Medellín y los puntos del cargue inicial\n",
    "# #     fig, ax = plt.subplots(figsize=(20, 20))\n",
    "# #     medellin_neighborhoods.plot(ax=ax, color='lightgrey', edgecolor='darkblue')\n",
    "# #     gdf_cargue.plot(ax=ax, color='blue', markersize=10, alpha=0.6)\n",
    "\n",
    "# #     plt.title('Datos simulados de ventas en Medellín y ubicaciones de clientes')\n",
    "# #     plt.xlabel('Longitud')\n",
    "# #     plt.ylabel('Latitud')\n",
    "# #     plt.grid(True)\n",
    "# #     plt.show()\n",
    "    \n",
    "# #     # Guardar la figura en un archivo si la visualización es correcta\n",
    "# #     plt.savefig('./data/medellin_neighborhoods_simulacion.png')\n",
    "# #     plt.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al convertir o visualizar los datos con GeoPandas: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2131524-8aa5-44b3-80ad-0e1f2409dbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
